# What is information?
1. Surprise!
1. The number of bits a file/object occupies
1. Knowledge, measured in length of white beard
1. Total number of published papers

# Imagine a process with 3 possible outcomes. The case of highest entropy is
1. p₁ = p₂ = p₃ = 1/3
1. p₁ = 1, p₂ = p₃ = 0
1. p₁ = 0.5, p₂ = 0.3, p₃ = 0.2
1. p₁ = p₂ = 0.5, p₃ = 0

# Why does the scaling of the generalized entropy of a finite dataset break at small scales?
1. The fine structure of a chaotic set cannot be resolved with 64-bit numbers
1. Below a minimum scale δ the entropy saturates to maximum value
1. Below a minimum scale δ the entropy saturates to minimum value
1. Trick question, the scaling does not break

# We obtain numbers from uniform random number generator and make two-dimensional vectors with them. In the limit of creating infinite vectors, the resulting dataset will have fractal dimension of
1. ∈ [0, 1)
1. Exactly = 1
1. ∈ (1, 2)
1. Exactly = 2

# The fractal boundary of Fig. 5.4 (which comes from a four dimensional system) has fractal dimension in the range
1. [0, 1]
1. (1, 2]
1. (2, 3]
1. (3, 4]
