# What is information?
1. Surprise
1. The number of bits a file occupies
1. Knowledge, measured in length of white beard
1. Total number of published papers

# Imagine a process with 3 possible outcomes. The case of highest entropy is
1. p₁ = p₂ = p₃ = 1/3
1. p₁ = 1, p₂ = p₃ = 0
1. p₁ = 0.5, p₂ = 0.3, p₃ = 0.2
1. p₁ = p₂ = 0.5, p₃ = 0

# The fractal boundary of Fig. 5.4 (which comes from a four dimensional system) has fractal dimension in the range
1. [0, 1]
1. (1, 2]
1. (2, 3]
1. (3, 4]

# Why does the scaling of the generalized entropy break at small scales?
1. Because the fine structure of a chaotic set cannot be resolved with 64-bit numbers
1. Because below a minimum scale $$δ$$ entropy saturates to maximum value
1. Because below a minimum scale $$δ$$ entropy saturates to minimum value
1. Trick question, the scaling does not break

# We obtain numbers from uniform random number generator and make three-dimensional vectors with them. In the limit of creating infinite vectors, the resulting dataset will have fractal dimension of
1. ∈ [0, 1)
1. Exactly = 1
1. ∈ (1, 3)
1. Exactly = 3
